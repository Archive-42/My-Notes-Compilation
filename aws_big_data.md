#### 1. What is a data lake?

- \[\] A unique and resilient object storage class of Amazon $3.
- \[✅\] A centralized repository that allows you to store all your structured and unstructured data at any scale.
- \[\] A centralized repository that allows you to work on code with other developers simultaneously, at any scale.
- \[\] A persisted and self-analyzing object storage class of Amazon S3.

#### 2. What Amazon service provides container and auto-scaling in a single package?

- \[✅\] The Amazon Elastic Container service.
- \[\] The Amazon Redshift clusters.
- \[\] The Amazon Polly interpreter.
- \[\] The Amazon Node Container service.

#### 3. Below is a AWS CLI command with Apache Spark:

aws emr create-cluster –name “Spark Spark” –release-label emr-5.19.0 —applications Name=Spark  
–ec2-attributes KeyName=myKey –instance-type m4.large –instance-count 3 –use-default-roles

- \[\] It is creating a new Spark classification.
- \[✅\] It is creating a new Spark cluster.
- \[\] It is creating a new Spark role.
- \[\] It is creating a new Spark node.

#### 4. Under what circumstance should you choose Amazon Glacier storage?

- \[✅\] If you have data that needs to be archived or does not need real-time access.
- \[\] If you have data that is going to injected into machine learning models.
- \[\] If you have data that needs to be streamed real-time with very low latency, like news broadcasts.
- \[\] If you have data that needs processing for big data purposes.

#### 5. Why is the partition-key design so important in table performance?

- \[\] Because it forces analysis on discreet object performance.
- \[\] Because it defines MAC address routing amongst multiple nodes.
- \[\] Because it allows manipulation of table asset modifiers.
- \[✅\] Because it defines how information in the table can be looked up.

#### 6. What is a bucket in Amazon S3?

- \[✅\] A fundamental container for storage.
- \[\] A managed object analysis unit.
- \[\] A Hadoop powered analysis engine.
- \[\] A big data processing container.

#### 7. What function do ETL jobs perform?

- \[\] ETL jobs are simply shell scripts that activate functions within a big data application that perform some task.
- \[✅\] They are a means to extract data from a source, transform the data in some way, and load it to a target.
- \[\] They are a means to extrapolate data from a source, transmit the data in some way, and launch the application.
- \[\] ETL jobs are simply python scripts analyzing big data applications through machine learning models.

#### 8. The following is code written in Java for Amazon ES:

- \[\] It is creating anew esClient named RestClient with a service name and region.
- \[\] It is establishing a baseline service name and region for an Amazon service.
- \[✅\] It is creating a new RestClient named esClient with a service name and region.
- \[\] It is configuring a region requisition for a specific Amazon ES service.

#### 9. What two factors can trigger an ETL job in Amazon Glue?

- \[\] Events and form factor.
- \[\] Placement and routing.
- \[✅\] Events and schedules.
- \[\] Routing and schedules.

#### 10. How is work completed in Amazon EMR?

- \[\] Through the use of elastic load balancers.
- \[\] Through the use of cluster and nodes of Amazon AMIs.
- \[✅\] Through the use of clusters and nodes of Amazon EC2 instances.
- \[\] Through the use of reserved instances.

#### 11. Shiraz has been working with an S3 data lake and Amazon Glue for a big dataapplication a client in finance. He is setting up a new database with new partitions and tables that ingests historical stock data. When performing a new query, he receives a HIve_PARTITION_SCHEMA_MIsmATcH error. Why is this

- \[\] The schema of the database is missing an S3 designation.
- \[\] The database schema is overlapping.
- \[\] The column schema is overlapping.
- \[✅\] The schema of the partitions differ from the schema of the tables.

#### 12. Below is an example of code from Amazon Kinesis:

- \[\] createStreamRequest.setStreamName( myStreamName )
- \[\] createStreamRequest.setShardcount( myStreamSize );
- \[\] It is creating a CloudWatch stream request to link with a steam name in Kinesis.
- \[\] It is creating a Redshift stream request to link with a stream name in Kinesis.
- \[✅\] It is creating a Kinesis stream request with a name and shard count.
- \[\] It is creating a DynamoDB stream request with a name and shard count.

#### 13. Below is a POST request in Amazon ES:

- \[\] polly search.
- \[\] movie.
- \[\] movies.
- \[✅\] spirit7.

#### 14. What are the two types of control you can issue in Amazon Redshift?

- \[\] Role-based and sort-based access.
- \[\] Position-based and core-based access.
- \[\] Position-based and sort-based access.
- \[✅\] Role-based and key-based access.

#### 15. What is the default storage class chosen for new objects uploaded to Amazon S3?

- \[✅\] STANDARD.
- \[\] RRS.
- \[\] STANDARD_IA.
- \[\] REGULAR.

#### 16. What is a benefit of AWS Direct Connect?

- \[\] Less costly data audits.
- \[✅\] More consistent network performance.
- \[\] More consistent data retention.
- \[\] Less elastic overhead.

#### 17. Melanie is configuring a JDBC client to connect with her Amazon Redshift cluster. After she finishes provisioning the connection, she sets her initial call request. When the request comes back, it is providing a client-side-out-of-memory error instead of the query results. Generally speaking, why is this

- \[\] Melanie does not have IAM access to the Amazon Redshift cluster.
- \[\] One of Melanie’s queries is too large. She needs to try sending the entire request again.
- \[\] Melanie does not have the right AWS account type to support the load her request needs.
- \[✅\] There is too much query data to collect and Melanie needs to send her requests in batches.

#### 18. If you want to increase Kinesis processing for a large scale application, what must you do first?

- \[✅\] Request a KPU limit increase from AWS.
- \[\] Request a system upgrade from an AWS architect.
- \[\] Provide a new connection to DynamoDB.
- \[\] Provide a new fork in the main AWS account for the service.

#### 19. What is the purpose of object versioning?

- \[\] It is used to archive objects and stop object misappropriation.
- \[\] It is used to understand when an object is no longer valid.
- \[✅\] It is used to archive objects and prevent unintended deletion of data.
- \[\] It is used to understand when an object can no longer handle the state of the application.

#### 20. How can you avoid client-side-out-of-memory errors when using JDBC in Redshift?

- \[✅\] Enable your client to fetch data in batches by setting the JDBC fetch size parameter.
- \[\] Enable your client to fetch data at once by setting the JDBC fetch size.
- \[\] Enable your client to produce an AWS authorizer that will allow greater fetch loads.
- \[\] Enable your client to change AWS client fetch settings to increase load.

#### 21. What are the two backup mechanisms in DynamoDB?

- \[\] Haste backups and ready recovery.
- \[\] Ready recovery and cron backup.
- \[\] On-demand recovery points and JIT backups.
- \[✅\] On-demand backups and point-in-time recovery.

#### 22. When creating a new table, what must you have already set up in order finish the request?

- \[\] An AWS Architect Account.
- \[✅\] A database.
- \[\] A CloudFront log.
- \[\] A table prefix.

#### 23. What is a database schema?

- \[\] Software for handling abstractions in data.
- \[\] A method for handling software mechanisms.
- \[\] Software for handling data in a discreet application.
- \[✅\] A method for storing data in a specific way.

#### 24. What Athena Query Editor statement forms a new database?

- \[\] DATABASE.
- \[\] FORM DATABASE.
- \[✅\] CREATE DATABASE.
- \[\] FORM.

#### 25. What is indexing?

- \[\] It is the method by which operating systems produce sets of data in a specific order.
- \[✅\] It is the method by which search engines organize data for fast retrieval.
- \[\] It is the method by which Amazon hosts search data for Elasticsearch services.
- \[\] It is the method by which Amazon facilitates connections between new, external services.

The following is an example of code from Amazon CloudWatch with Amazon CloudFormation: “Alarm”: { “Type”: “AWS::CloudWatch::Alarm”, “Properties”: { “AlarmDescription”: { “Fn::Join”: \["“, \[ "Alarm if AWS spending is over $", { "Ref": "AlarmThresholdValue" }\]\]},”Namespace“:”AWS/Billing“,”MetricName“:”EstimatedCharges“,”Dimensions“: \[{ "Name": "Currency", "Value" : "USD" }\],”Statistic“:”Maximum“,”Period“:”21600“, “EvaluationPeriods”: “1”, “Threshold”: { “Ref”: “AlarmThresholdValue” }, “ComparisonOperator”: ““GreaterThanThreshold”, “AlarmActions”: \[ { “Ref”: “BillingAlarmNotification” }\], “InsufficientDataActions”: \[ { “Ref”: “BillingAlarmNotification” }\], }

}

#### 26. In general, what is this code doing?

- \[\] It is setting a policy for eventual downgrades in service based on AWS thresholds in order to save cost.
- \[\] It is adjusting service levels based on when charges to an AWS account exceed the alarm threshold.

- \[✅\] It is sending notifications whens charges to an AWS account exceed the alarm threshold.

- \[\] It is stopping AWS services until user input if charge exceed the alarm threshold.

#### 27. What is this policy doing?

{ “Version”: “2012-10-17”, “Statement”: \[ { “Sid”: “Stmt1473028104000”, “Effect”: “Allow”, “Action”: \[ “kinesisanalytics:CreateApplication” 1, “Resource”: \[ "\*"\] }\] }

- \[✅\] Allowing access to the “CreateApplication” action on Amazon Kinesis on all resources.

- \[\] Providing access to the ARN “Stmt1473028104000”.
- \[\] Allowing access to the “CreateApplication” action on Amazon Kinesis.
- \[\] Providing the basis for the Amazon Kinesis version.
