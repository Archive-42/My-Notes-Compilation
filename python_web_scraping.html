<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes"
    />
    <title>python_web_scraping</title>
    <style type="text/css">
      code {
        white-space: pre-wrap;
      }
      span.smallcaps {
        font-variant: small-caps;
      }
      span.underline {
        text-decoration: underline;
      }
      div.column {
        display: inline-block;
        vertical-align: top;
        width: 50%;
      }
    </style>
    <style type="text/css">
      a.sourceLine {
        display: inline-block;
        line-height: 1.25;
      }
      a.sourceLine {
        pointer-events: none;
        color: inherit;
        text-decoration: inherit;
      }
      a.sourceLine:empty {
        height: 1.2em;
      }
      .sourceCode {
        overflow: visible;
      }
      code.sourceCode {
        white-space: pre;
        position: relative;
      }
      div.sourceCode {
        margin: 1em 0;
      }
      pre.sourceCode {
        margin: 0;
      }
      @media screen {
        div.sourceCode {
          overflow: auto;
        }
      }
      @media print {
        code.sourceCode {
          white-space: pre-wrap;
        }
        a.sourceLine {
          text-indent: -1em;
          padding-left: 1em;
        }
      }
      pre.numberSource a.sourceLine {
        position: relative;
        left: -4em;
      }
      pre.numberSource a.sourceLine::before {
        content: attr(title);
        position: relative;
        left: -1em;
        text-align: right;
        vertical-align: baseline;
        border: none;
        pointer-events: all;
        display: inline-block;
        -webkit-touch-callout: none;
        -webkit-user-select: none;
        -khtml-user-select: none;
        -moz-user-select: none;
        -ms-user-select: none;
        user-select: none;
        padding: 0 4px;
        width: 4em;
        color: #aaaaaa;
      }
      pre.numberSource {
        margin-left: 3em;
        border-left: 1px solid #aaaaaa;
        padding-left: 4px;
      }
      div.sourceCode {
      }
      @media screen {
        a.sourceLine::before {
          text-decoration: underline;
        }
      }
      code span.al {
        color: #ff0000;
        font-weight: bold;
      } /* Alert */
      code span.an {
        color: #60a0b0;
        font-weight: bold;
        font-style: italic;
      } /* Annotation */
      code span.at {
        color: #7d9029;
      } /* Attribute */
      code span.bn {
        color: #40a070;
      } /* BaseN */
      code span.bu {
      } /* BuiltIn */
      code span.cf {
        color: #007020;
        font-weight: bold;
      } /* ControlFlow */
      code span.ch {
        color: #4070a0;
      } /* Char */
      code span.cn {
        color: #880000;
      } /* Constant */
      code span.co {
        color: #60a0b0;
        font-style: italic;
      } /* Comment */
      code span.cv {
        color: #60a0b0;
        font-weight: bold;
        font-style: italic;
      } /* CommentVar */
      code span.do {
        color: #ba2121;
        font-style: italic;
      } /* Documentation */
      code span.dt {
        color: #902000;
      } /* DataType */
      code span.dv {
        color: #40a070;
      } /* DecVal */
      code span.er {
        color: #ff0000;
        font-weight: bold;
      } /* Error */
      code span.ex {
      } /* Extension */
      code span.fl {
        color: #40a070;
      } /* Float */
      code span.fu {
        color: #06287e;
      } /* Function */
      code span.im {
      } /* Import */
      code span.in {
        color: #60a0b0;
        font-weight: bold;
        font-style: italic;
      } /* Information */
      code span.kw {
        color: #007020;
        font-weight: bold;
      } /* Keyword */
      code span.op {
        color: #666666;
      } /* Operator */
      code span.ot {
        color: #007020;
      } /* Other */
      code span.pp {
        color: #bc7a00;
      } /* Preprocessor */
      code span.sc {
        color: #4070a0;
      } /* SpecialChar */
      code span.ss {
        color: #bb6688;
      } /* SpecialString */
      code span.st {
        color: #4070a0;
      } /* String */
      code span.va {
        color: #19177c;
      } /* Variable */
      code span.vs {
        color: #4070a0;
      } /* VerbatimString */
      code span.wa {
        color: #60a0b0;
        font-weight: bold;
        font-style: italic;
      } /* Warning */
    </style>
  </head>
  <body>
    <h4
      id="why-is-the-scrapy-spider-class-crawlspider-good-for-generic-website-crawling"
    >
      1. Why is the scrapy spider class crawlspider good for generic website
      crawling?
    </h4>
    <ul>
      <li>
        [✅] It comes with generic mechanisms for crawling links by a set of
        predefined common rules.
      </li>
      <li>
        [] It contains a skeleton class that does not contain a predefined set
        of rules, which is good for complicated sets that require customization
      </li>
      <li>
        [] It comes with un-customizable mechanisms for crawling links by a long
        list of rules.
      </li>
      <li>
        [] It comes with specific mechanisms for crawling links by a set of
        predefined custom rules.
      </li>
    </ul>
    <h4 id="what-do-the-following-lines-of-code-produce">
      2. What do the following lines of code produce?
    </h4>
    <div class="sourceCode" id="cb1">
      <pre
        class="sourceCode python"
      ><code class="sourceCode python"><a class="sourceLine" id="cb1-1" title="1">soup <span class="op">=</span> Beautiful Soup(<span class="st">&quot;&quot;&quot; &lt;p&gt; &lt;a href=&quot;https: //www.wikipedia.org&#39;&gt;link &lt;/a&gt;&lt;/p&gt;&quot;&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb1-2" title="2">soup.find(<span class="st">&#39;a&#39;</span>)</a></code></pre>
    </div>
    <ul>
      <li>[] https://wmw.wikipedia.org</li>
      <li>[✅] <a href="https://www.wikipedia.org">link </a></li>
      <li>[] &gt;link</li>
      <li>
        []
        <h1>Wikipedia</h1>
      </li>
    </ul>
    <h4
      id="which-code-snippet-will-create-a-custom-pipeline-class-that-will-return-a-warning-when-no-header-is-found-in-the-spiderperson-spider-but--will-still-return-the-item"
    >
      3. Which code snippet will create a custom pipeline class that will return
      a warning when no header is found in the SpiderPerson spider, but -will
      still return the item
    </h4>
    <ul>
      <li>[✅] class pipelineProcessorWarning(object):</li>
    </ul>
    <div class="sourceCode" id="cb2">
      <pre
        class="sourceCode python"
      ><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">def</span> process_item(<span class="va">self</span>, item, SpiderPerson):</a>
<a class="sourceLine" id="cb2-2" title="2">SpiderPerson. logger .warn(<span class="st">&#39;{@}&#39;</span>.<span class="bu">format</span>(item.get(<span class="st">&#39;header&#39;</span>, <span class="st">&#39;No header was found&#39;</span>)))</a>
<a class="sourceLine" id="cb2-3" title="3"><span class="cf">return</span> item</a></code></pre>
    </div>
    <ul>
      <li>[] class pipelineProcessorWarning(item) :</li>
    </ul>
    <div class="sourceCode" id="cb3">
      <pre
        class="sourceCode python"
      ><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1"><span class="kw">def</span> processer_item(SpiderPerson):</a>
<a class="sourceLine" id="cb3-2" title="2">SpiderPerson.logger.warn(<span class="st">&#39;</span><span class="sc">{0}</span><span class="st">&#39;</span>.<span class="bu">format</span>(item.get(<span class="st">&#39;header&#39;</span>, <span class="st">&#39;No header was found&#39;</span>)))</a></code></pre>
    </div>
    <ul>
      <li>[] class pipelineProcessorWarning(object):</li>
    </ul>
    <div class="sourceCode" id="cb4">
      <pre
        class="sourceCode python"
      ><code class="sourceCode python"><a class="sourceLine" id="cb4-1" title="1">process_item(<span class="va">self</span>, item, SpiderPerson):</a>
<a class="sourceLine" id="cb4-2" title="2">SpiderPerson.logger.warn(<span class="st">&#39;</span><span class="sc">{0}</span><span class="st">&#39;</span>.<span class="bu">format</span>(item.get(<span class="st">&#39;header&#39;</span>, <span class="st">&#39;No header was found&#39;</span>)))</a>
<a class="sourceLine" id="cb4-3" title="3"><span class="cf">return</span> <span class="bu">object</span></a></code></pre>
    </div>
    <ul>
      <li>[] Function(pipelineProcessorWarning(object)) :</li>
    </ul>
    <div class="sourceCode" id="cb5">
      <pre
        class="sourceCode python"
      ><code class="sourceCode python"><a class="sourceLine" id="cb5-1" title="1">method <span class="kw">class</span> process_item(<span class="va">self</span>, item, SpiderPerson):</a>
<a class="sourceLine" id="cb5-2" title="2">SpiderPerson. logger .warn(<span class="st">&#39;{@}&#39;</span>.<span class="bu">format</span>(item.get(<span class="st">&#39;header&#39;</span>, <span class="st">&#39;No header was found&#39;</span>)))</a>
<a class="sourceLine" id="cb5-3" title="3"><span class="cf">return</span> <span class="bu">object</span></a></code></pre>
    </div>
    <h4 id="what-is-true-regarding-overriding-pipeline-methods">
      4. What is true regarding overriding pipeline methods?
    </h4>
    <ul>
      <li>[] nly one method can be overridden when using Beautiful Soup</li>
      <li>[✅] All pipeline methods can be overridden</li>
      <li>[] nly private pipeline methods can be overridden</li>
      <li>[] nly the data store method can be overridden</li>
    </ul>
    <h4
      id="you-create-a-web-scraping-application-that-uses-beautiful-soup-to-scrape-information-from-a-media-webpage.-a-co-worker-uses-a-different-scraping-library-to--scrape-the-same-webpage-however-their-resulting-dataset-is"
    >
      5. You create a web scraping application that uses Beautiful Soup to
      scrape information from a media webpage. A co-worker uses a different
      scraping library to -scrape the same webpage; however, their resulting
      dataset is
    </h4>
    <p>
      different than yours. How could this have happened - [] Different versions
      of Python create different parsed documents. - [] Different web standards
      could create different parsed documents. - [✅] Different parsers create
      different HTML/XML documents. - [] Different versions of Beautiful Soup
      create different parsed documents.
    </p>
    <h4
      id="why-is-beautiful-soup-preferred-for-scraping-static-pages-when-selenium-could-be-used-for-everything"
    >
      6. Why is Beautiful Soup preferred for scraping static pages when Selenium
      could be used for everything?
    </h4>
    <ul>
      <li>
        [] Developing code with Beautiful Soup is much easier to scrape static
        pages than it is with Selenium
      </li>
      <li>
        [] Beautiful Soup renders static pages better when compared to Selenium.
      </li>
      <li>
        [] Selenium takes more time while scraping static pages than Beautiful
        Soup.
      </li>
      <li>
        [✅] While scraping static pages, it is not necessary to render it in a
        browser.
      </li>
    </ul>
    <h4
      id="which-type-of-classes-can-be-defined-in-scrapy-to-scrape-data-from-a-website"
    >
      7. Which type of classes can be defined in Scrapy to scrape data from a
      website?
    </h4>
    <ul>
      <li>[] Knife Class</li>
      <li>[] Scratch Class</li>
      <li>[] Crawler Class</li>
      <li>[✅] Spider Class</li>
    </ul>
    <h4
      id="what-is-currently-the-only-supported-parser-in-beautiful-soup-for-dealing-with-extensible-markup-language"
    >
      8. What is currently the only supported parser in Beautiful Soup for
      dealing with extensible markup language?
    </h4>
    <ul>
      <li>[] html. parser</li>
      <li>[] json.parser</li>
      <li>[] htm151ib</li>
      <li>[✅] Lxml-xml</li>
    </ul>
    <h4 id="what-ixml-method-would-allow-us-to-find-html-page-elements">
      9. What Ixml method would allow us to find HTML page elements?
    </h4>
    <ul>
      <li>[] XMLSchema</li>
      <li>[✅] XPath</li>
      <li>[] RelaxNG</li>
      <li>[] Schematron</li>
    </ul>
    <h4
      id="you-need-to-find-all-hl-header-attributes-in-a-web-page.-how-can-this-be-accomplished-using-beautiful-soup"
    >
      10. You need to find all ‘hl’ header attributes in a web page. How can
      this be accomplished using Beautiful Soup?
    </h4>
    <ul>
      <li>
        [] soup.find_all(‘hi’.[attrs]) to return all hl headers attributes.
      </li>
      <li>
        [✅] soup.find_all(‘h1’).attrs to return all hl header attributes.
      </li>
      <li>
        [] soup.find_all(‘h1’).[attribute] to return all hl headers attributes.
      </li>
      <li>[] soup.find(‘h1’).attrs to return all hl header attributes.</li>
    </ul>
    <h4
      id="which-line-of-code-is-next-when-trying-to-discover-the-content-type"
    >
      11. Which line of code is next when trying to discover the content type?
    </h4>
    <div class="sourceCode" id="cb6">
      <pre
        class="sourceCode python"
      ><code class="sourceCode python"><a class="sourceLine" id="cb6-1" title="1">r <span class="op">=</span> requests.get(<span class="st">&#39;https://api.github.com/user&#39;</span>, auth<span class="op">=</span>(<span class="st">&#39;user&#39;</span>, <span class="st">&#39;pass&#39;</span>))</a></code></pre>
    </div>
    <ul>
      <li>[] r.[‘content-type’]</li>
      <li>[] return [‘content-type’]</li>
      <li>[✅] r.headers[ ‘content-type’]</li>
      <li>[] r.get[‘content-type’]</li>
    </ul>
    <h4
      id="you-start-web-scraping-several-sites-with-beautiful-soup-and-notice-that-much-of-the-data-you-received-is-malformed-or-has-no-html-body.-if--you-are-using-the-default-html-parser-what-could-you-do-to-improve-your-parsing"
    >
      12. You start web scraping several sites with Beautiful Soup and notice
      that much of the data you received is malformed or has no HTML body. If
      -you are using the default HTML parser, what could you do to improve your
      parsing
    </h4>
    <ul>
      <li>
        [] Scan other web pages. The HTML tags in their web sites are malformed,
        causing the parser to fail
      </li>
      <li>
        [] Import Ixml’s XML parser. It is more lenient on XML elements and can
        better handle broken XML tags.
      </li>
      <li>
        [] Import Python’s HTML parser. It is more lenient on HTML elements and
        can better handle broken HTML tags.
      </li>
      <li>
        [✅] Import Ixml’s HTML parser. It is more lenient on HTML elements and
        can better handle broken HTML tags.
      </li>
    </ul>
    <h4
      id="when-attempting-to-download-a-media-file-using-the-built-in-python-library-urllib.request-what-step-comes-after-opening-the-url-file"
    >
      13. When attempting to download a media file using the built-in Python
      library urllib.request , what step comes after opening the URL file?
    </h4>
    <ul>
      <li>[] Read the file with .ingest()</li>
      <li>[✅] Read the url file with .read()</li>
      <li>[] Parse the file with .parse()</li>
      <li>[] Save the file with .save()</li>
    </ul>
    <h4
      id="which-procedure-generally-does-not-apply-to-web-scraping-analytical-data-from-a-web-page"
    >
      14. Which procedure generally does not apply to web scraping analytical
      data from a web page?
    </h4>
    <ul>
      <li>[✅] Importing data into a web page using the urllib library</li>
      <li>[] Accessing the tag names of the HTML using name</li>
      <li>
        [] Exporting results to an external files, such as a CSV, XML, or JSN
      </li>
      <li>[] Cleaning HTML data by stripping or replacing unnecessary data</li>
    </ul>
    <h4 id="what-is-a-supported-parser-for-beautiful-soup">
      15. What is a supported parser for Beautiful Soup?
    </h4>
    <ul>
      <li>[] Iparser</li>
      <li>[✅] html.parser</li>
      <li>[] htmllib</li>
      <li>[] xml.parse</li>
    </ul>
    <h4 id="when-might-you-want-to-use-the-html5lib-parser-with-beautiful-soup">
      16. When might you want to use the html5lib parser with Beautiful Soup?
    </h4>
    <ul>
      <li>[✅] To create valid objects from HTML5 when parsing</li>
      <li>[] To parse newer page elements like XML and JSN</li>
      <li>[] To parse older page elements like headers and lists</li>
      <li>[] To avoid external library dependencies</li>
    </ul>
    <h4
      id="how-could-you-add-exception-handling-to-check-if-your-beautiful-soup-parser-is-unable-to-connect-to-a-website"
    >
      17. How could you add exception handling to check if your Beautiful Soup
      parser is unable to connect to a website?
    </h4>
    <ul>
      <li>
        [] Check for an HTTP status code of 200. If it’s true, throw an
        exception.
      </li>
      <li>
        [✅] Check for an HTTP status code of 200. If it’s false, throw an
        exception
      </li>
      <li>
        [] Check for an HTTP status code of 101. If it’s true, throw an
        exception.
      </li>
      <li>
        [] Check for an HTTP status code of 400. If it’s false, throw an
        exception.
      </li>
    </ul>
    <h4
      id="you-need-to-search-through-a-long-html-document-and-find-all-of-the-mentioned-numbers.-how-could-you-utilize-beautiful-soup-and-regex-to--parse-for-this-specific-data"
    >
      18. You need to search through a long HTML document and find all of the
      mentioned numbers. How could you utilize Beautiful Soup and regex to
      -parse for this specific data
    </h4>
    <ul>
      <li>
        [] Use Beautiful Soup’s find_all() method to look for values with a
        regex of () or [ to grab all decimal values.
      </li>
      <li>
        [] Use Beautiful Soup’s find_all() method to look for values with a
        regex of () or [^a-zA-Z0-9_] to grab all decimal values.
      </li>
      <li>
        [] Use Beautiful Soup’s find_all() method to look for values with a
        regex of () or [^0-9] to grab all decimal values.
      </li>
      <li>
        [✅] Use Beautiful Soup’s find_all() method to look for values with a
        regex of ( or [0-9] to grab all decimal values.
      </li>
    </ul>
  </body>
</html>
